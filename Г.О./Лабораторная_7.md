# ĞĞ°Ğ·Ğ°Ñ€Ğ¾Ğ²Ğ° Ğ”Ğ°Ñ€ÑŒÑ
## Ğ›Ğ°Ğ±Ğ¾Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° â„–7




```python
import tensorflow as tf
# Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹

from tensorflow.keras import layers, models, optimizers, metrics, callbacks  # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹ Ğ¸Ğ· Keras
# - layers: Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑĞ»Ğ¾ĞµĞ² Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ¹ ÑĞµÑ‚Ğ¸,
# - models: Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸,
# - optimizers: Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ° Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸,
# - metrics: Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸,
# - callbacks: Ğ´Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.

import numpy as np  #  Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¼ĞµÑ€Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ°Ğ¼Ğ¸, Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ğ°Ğ¼Ğ¸, Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ÑĞ¼Ğ¸.

import matplotlib.pyplot as plt  # Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ²

```


```python
(train_images, _), (_, _) = tf.keras.datasets.fashion_mnist.load_data()
# Ğ½Ğ°Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¾Ğ´ĞµĞ¶Ğ´Ñ‹.
# Ğ±ĞµÑ€Ñƒ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ (train_images)

train_images = (train_images.astype("float32") - 127.5) / 127.5
# Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¸Ğ¿Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ² float32
# Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹ Ğ¸Ğ· Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° [0, 255] Ğ² Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ [-1, 1]
# Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

train_images = np.expand_dims(train_images, axis=-1)
# Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ Ğº Ğ¼Ğ°ÑÑĞ¸Ğ²Ñƒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹

batch_size = 64  # Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±Ğ°Ñ‚Ñ‡Ğ° Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

train_dataset = (
    tf.data.Dataset.from_tensor_slices(train_images)  # Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ğ¸Ğ· Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ğ¾Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
    .shuffle(60000)
    .batch(batch_size)  # Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ğ±Ğ°Ñ‚Ñ‡Ğ¸ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°
)
```


```python
def build_generator(latent_dim):  # Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
    model = models.Sequential([  # Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ¸Ğ· Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… ÑĞ»Ğ¾ĞµĞ²
        layers.Dense(7 * 7 * 256, use_bias=False, input_dim=latent_dim),
        # Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½Ñ‹Ğ¹ ÑĞ»Ğ¾Ğ¹ Ñ 7 * 7 * 256 Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ°Ğ¼Ğ¸
        # use_bias=False ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, Ñ‡Ñ‚Ğ¾ ÑĞ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ Ğ½Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ² ÑÑ‚Ğ¾Ğ¼ ÑĞ»Ğ¾Ğµ

        layers.BatchNormalization(),  # Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ñ‚Ñ‡Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
        layers.LeakyReLU(),  # Leaky ReLU Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ

        layers.Reshape((7, 7, 256)),

        layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding="same", use_bias=False),
        # Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ²ĞµÑ€Ñ‚ĞºĞ° Ñ 128 Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ¸ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ¼ ÑĞ´Ñ€Ğ° (5, 5)
        # strides=(1, 1) Ğ¸ padding="same" Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°

        layers.BatchNormalization(), # Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ñ‚Ñ‡Ğ° Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
        layers.LeakyReLU(),

        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding="same", use_bias=False),
        # Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ²ĞµÑ€Ñ‚Ğ¾Ğº Ñ 64 Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼Ğ¸, ÑƒĞ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ²Ğ°Ñ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ²Ğ° Ñ€Ğ°Ğ·Ğ° (strides=(2, 2))

        layers.BatchNormalization(),  # Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ñ‚Ñ‡Ğ°
        layers.LeakyReLU(),

        layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding="same", activation="tanh")
    ])
    return model

```


```python
def build_critic():  # Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ° (Ğ´Ğ¸ÑĞºÑ€Ğ¸Ğ¼Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€Ğ°)
    model = models.Sequential([  # Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸Ğ· Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… ÑĞ»Ğ¾ĞµĞ²
        layers.Conv2D(64, (5, 5), strides=(2, 2), padding="same", input_shape=[28, 28, 1]),
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ²ĞµÑ€Ñ‚ĞºÑƒ (Conv2D) Ñ 64 Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ¸ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ¼ ÑĞ´Ñ€Ğ° (5, 5)
        # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ strides=(2, 2) ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ÑÑ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ²Ğ´Ğ²Ğ¾Ğµ
        # padding="same" ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€. Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ²Ñ…Ğ¾Ğ´Ğ½ÑƒÑ Ñ„Ğ¾Ñ€Ğ¼Ñƒ [28, 28, 1] Ğ´Ğ»Ñ Ñ‡ĞµÑ€Ğ½Ğ¾-Ğ±ĞµĞ»Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹

        layers.LeakyReLU(),  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Leaky ReLU Ğ´Ğ»Ñ Ğ²Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ.
        layers.Dropout(0.3),  # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ ÑĞ»Ğ¾Ğ¹ Dropout Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒÑ 0.3 Ğ´Ğ»Ñ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.

        layers.Conv2D(128, (5, 5), strides=(2, 2), padding="same"),
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞµÑ‰Ğµ Ğ¾Ğ´Ğ½Ñƒ ÑĞ²ĞµÑ€Ñ‚ĞºÑƒ Ñ 128 Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ğ¼Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ‚Ğ°ĞºĞ¶Ğµ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.

        layers.LeakyReLU(),  # Ğ¡Ğ½Ğ¾Ğ²Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Leaky ReLU ĞºĞ°Ğº Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ.
        layers.Dropout(0.3),  # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Dropout Ğ´Ğ»Ñ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.

        layers.Flatten(), # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ 3D-Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€ (Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ) Ğ² 1D-Ğ²ĞµĞºÑ‚Ğ¾Ñ€, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ñ.

        layers.Dense(1),  # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½Ñ‹Ğ¹ ÑĞ»Ğ¾Ğ¹ (Dense) Ñ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¾Ğ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ (Ğ¸Ğ· Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ĞµĞ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°) Ğ¸Ğ»Ğ¸ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼.
    ])
    return model  # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°.

```


```python
class WGANGP(models.Model):  # ĞºĞ»Ğ°ÑÑ WGANGP Ğ½Ğ°ÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¾Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Keras
    def __init__(self, critic, generator, latent_dim, critic_steps=5, gp_weight=10):
        super(WGANGP, self).__init__()  # ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¾Ñ€ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ ĞºĞ»Ğ°ÑÑĞ°
        self.critic = critic  # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
        self.generator = generator
        self.latent_dim = latent_dim
        self.critic_steps = critic_steps
        self.gp_weight = gp_weight

    def compile(self, c_optimizer, g_optimizer):
        super(WGANGP, self).compile()  # Ğ¼ĞµÑ‚Ğ¾Ğ´ compile Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ ĞºĞ»Ğ°ÑÑĞ°
        self.c_optimizer = c_optimizer  # Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°
        self.g_optimizer = g_optimizer  # Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        self.c_loss_metric = metrics.Mean(name="c_loss")  # Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ
        self.g_loss_metric = metrics.Mean(name="g_loss")

    def gradient_penalty(self, real_images, fake_images):
        alpha = tf.random.normal([tf.shape(real_images)[0], 1, 1, 1], 0.0, 1.0)  # ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ°Ğ»ÑŒÑ„Ğ°-ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹
        interpolated = real_images + alpha * (fake_images - real_images)  # Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
        with tf.GradientTape() as tape:  # ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
            tape.watch(interpolated)  # Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
            pred = self.critic(interpolated)  # Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
        grads = tape.gradient(pred, [interpolated])[0]  # Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ÑĞ¼.
        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))  # Ğ½Ğ¾Ñ€Ğ¼Ğ° Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
        return tf.reduce_mean((norm - 1.0) ** 2)  # ÑÑ€ĞµĞ´Ğ½ĞµĞµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ ÑˆÑ‚Ñ€Ğ°Ñ„Ğ° Ğ·Ğ° Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹

    def train_step(self, real_images):
        batch_size = tf.shape(real_images)[0]  # Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±Ğ°Ñ‚Ñ‡Ğ° Ğ¸Ğ· Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹

        for _ in range(self.critic_steps):  # .
            random_latent_vectors = tf.random.normal([batch_size, self.latent_dim])  # ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ñ‹
            with tf.GradientTape() as tape:  # ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
                fake_images = self.generator(random_latent_vectors)  # Ñ„ĞµĞ¹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
                fake_pred = self.critic(fake_images)  # Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ñ„ĞµĞ¹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
                real_pred = self.critic(real_images)  # Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
                wass_loss = tf.reduce_mean(fake_pred) - tf.reduce_mean(real_pred)  # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸
                gp = self.gradient_penalty(real_images, fake_images)  # Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ ÑˆÑ‚Ñ€Ğ°Ñ„
                c_loss = wass_loss + gp * self.gp_weight  # ĞĞ±Ñ‰Ğ¸Ğµ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸
            grads = tape.gradient(c_loss, self.critic.trainable_variables)  # Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ
            self.c_optimizer.apply_gradients(zip(grads, self.critic.trainable_variables))  # Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹

        random_latent_vectors = tf.random.normal([batch_size, self.latent_dim])  # ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ñ‹
        with tf.GradientTape() as tape:  # ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
            fake_images = self.generator(random_latent_vectors)  # Ñ„ĞµĞ¹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
            fake_pred = self.critic(fake_images)  # Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ñ„ĞµĞ¹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹.
            g_loss = -tf.reduce_mean(fake_pred)  # Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        grads = tape.gradient(g_loss, self.generator.trainable_variables)  # Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))  # Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹

        self.c_loss_metric.update_state(c_loss)  # Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°
        self.g_loss_metric.update_state(g_loss)  # Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        return {"c_loss": self.c_loss_metric.result(), "g_loss": self.g_loss_metric.result()}

```


```python
latent_dim = 100  # Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°

# Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ñ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°
generator = build_generator(latent_dim)  #  build_generator Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°
critic = build_critic()  # build_critic Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°

# Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Wasserstein GAN Ñ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¼ ÑˆÑ‚Ñ€Ğ°Ñ„Ğ¾Ğ¼
wgan = WGANGP(critic=critic, generator=generator, latent_dim=latent_dim)

# Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
wgan.compile(
    c_optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9),  # ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°.
    g_optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9),  # ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°.
)

# Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
wgan.fit(train_dataset, epochs=50)  # 50 ÑĞ¿Ğ¾Ñ…

```

    /usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
      super().__init__(activity_regularizer=activity_regularizer, **kwargs)
    

    Epoch 1/50
    

    /usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
      super().__init__(activity_regularizer=activity_regularizer, **kwargs)
    

    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m96s[0m 81ms/step - c_loss: -8.6708 - g_loss: -8.4631
    Epoch 2/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 71ms/step - c_loss: -3.2808 - g_loss: -13.2420
    Epoch 3/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m82s[0m 71ms/step - c_loss: -2.4835 - g_loss: -8.9343
    Epoch 4/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -2.2010 - g_loss: -4.8260
    Epoch 5/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -2.1000 - g_loss: -5.3608
    Epoch 6/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.9429 - g_loss: -4.9012
    Epoch 7/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m82s[0m 71ms/step - c_loss: -1.8842 - g_loss: -2.6387
    Epoch 8/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m82s[0m 71ms/step - c_loss: -1.8311 - g_loss: -2.1450
    Epoch 9/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.7284 - g_loss: -2.6685
    Epoch 10/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m67s[0m 71ms/step - c_loss: -1.6925 - g_loss: -3.4164
    Epoch 11/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 71ms/step - c_loss: -1.7031 - g_loss: -1.7365
    Epoch 12/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.6465 - g_loss: -2.9038
    Epoch 13/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.5871 - g_loss: -1.3519
    Epoch 14/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m82s[0m 71ms/step - c_loss: -1.5617 - g_loss: -0.6062
    Epoch 15/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m82s[0m 71ms/step - c_loss: -1.5563 - g_loss: 0.3277
    Epoch 16/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.5009 - g_loss: 0.0117
    Epoch 17/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.5055 - g_loss: -0.8521
    Epoch 18/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.4758 - g_loss: -0.5205
    Epoch 19/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.4666 - g_loss: -0.2661
    Epoch 20/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.4125 - g_loss: 0.3304
    Epoch 21/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 71ms/step - c_loss: -1.4378 - g_loss: -0.4338
    Epoch 22/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.3810 - g_loss: 2.7651
    Epoch 23/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.3320 - g_loss: 2.0498
    Epoch 24/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.3885 - g_loss: 1.3660
    Epoch 25/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m82s[0m 71ms/step - c_loss: -1.3700 - g_loss: 0.8856
    Epoch 26/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.3333 - g_loss: 3.3099
    Epoch 27/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.3679 - g_loss: 5.7279
    Epoch 28/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 71ms/step - c_loss: -1.3153 - g_loss: 3.6858
    Epoch 29/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.3221 - g_loss: 3.2989
    Epoch 30/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.3210 - g_loss: 2.3823
    Epoch 31/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.2428 - g_loss: 1.7792
    Epoch 32/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.2655 - g_loss: 3.5605
    Epoch 33/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 71ms/step - c_loss: -1.2503 - g_loss: 3.0543
    Epoch 34/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.2855 - g_loss: 2.9978
    Epoch 35/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.2137 - g_loss: 1.4784
    Epoch 36/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.2523 - g_loss: 1.6313
    Epoch 37/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.1740 - g_loss: 1.3925
    Epoch 38/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.1665 - g_loss: 0.8290
    Epoch 39/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.1810 - g_loss: 2.1367
    Epoch 40/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.2545 - g_loss: 3.7186
    Epoch 41/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.1905 - g_loss: 2.1944
    Epoch 42/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.1553 - g_loss: 2.1372
    Epoch 43/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.1656 - g_loss: 1.2261
    Epoch 44/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.1535 - g_loss: 2.3463
    Epoch 45/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.2039 - g_loss: 3.2486
    Epoch 46/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m83s[0m 71ms/step - c_loss: -1.1738 - g_loss: 3.4035
    Epoch 47/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.1868 - g_loss: 5.0657
    Epoch 48/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.1428 - g_loss: 2.4350
    Epoch 49/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 71ms/step - c_loss: -1.1607 - g_loss: 3.5133
    Epoch 50/50
    [1m938/938[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m66s[0m 70ms/step - c_loss: -1.1306 - g_loss: 3.8242
    




    <keras.src.callbacks.history.History at 0x78fcb305e3b0>




```python
random_latent_vectors = tf.random.normal([16, latent_dim])  # 16 ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ñ… Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚Ğ¸ latent_dim

generated_images = generator(random_latent_vectors)  # Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²

# ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ· Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ° [-1, 1] Ğ² [0, 255] Ğº Ñ‚Ğ¸Ğ¿Ñƒ uint8
generated_images = (generated_images * 127.5 + 127.5).numpy().astype("uint8")

plt.figure(figsize=(4, 4))  # Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ¸Ğ³ÑƒÑ€Ñ‹ 4x4 Ğ´ÑĞ¹Ğ¼Ğ°
for i in range(16):
    plt.subplot(4, 4, i + 1)  # Ğ¿Ğ¾Ğ´Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¸Ğ· 16 Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹
    plt.imshow(generated_images[i, :, :, 0], cmap="gray")  # Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² Ğ³Ñ€Ğ°Ğ´Ğ°Ñ†Ğ¸ÑÑ… ÑĞµÑ€Ğ¾Ğ³Ğ¾
    plt.axis("off")  # Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾ÑĞµĞ¹
plt.show()
```


    
![png](output_7_0.png)
    

