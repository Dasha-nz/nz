{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f36ac352-439d-40b6-b0c9-feafd8c89e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a79029f-5a38-479d-9a12-a2fc249d7126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dasha\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttentionLayer(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.attention(inputs, inputs)\n",
    "\n",
    "def create_transformer_model(num_objects, embedding_dim, num_heads, ff_dim):\n",
    "    inputs = layers.Input(shape=(num_objects, embedding_dim))\n",
    "    \n",
    "    # Многоголовое внимание\n",
    "    attention_output = MultiHeadAttentionLayer(num_heads, embedding_dim)(inputs)\n",
    "    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output + inputs)\n",
    "    \n",
    "    # Полносвязный слой\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(ff_dim, activation='relu'),\n",
    "        layers.Dense(embedding_dim)\n",
    "    ])\n",
    "    ffn_output = ffn(attention_output)\n",
    "    ffn_output = layers.LayerNormalization(epsilon=1e-6)(ffn_output + attention_output)\n",
    "    \n",
    "    # Выходной слой\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(ffn_output)  # Для бинарной классификации (например, \"близко\" или \"далеко\")\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Параметры модели\n",
    "num_objects = 10  # Количество объектов\n",
    "embedding_dim = 16  # Размерность векторного представления\n",
    "num_heads = 4  # Количество голов в многоголовом внимании\n",
    "ff_dim = 32  # Размерность скрытого слоя\n",
    "\n",
    "# Создание модели\n",
    "model = create_transformer_model(num_objects, embedding_dim, num_heads, ff_dim)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbc34e6-bd54-4f3f-adcc-fd2d94cb9a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Dasha/Desktop/CLEVR_v1.0\\CLEVR_train_questions.json\n",
      "C:/Users/Dasha/Desktop/CLEVR_v1.0\\CLEVR_val_questions.json\n",
      "Количество вопросов: 849980\n",
      "Пример вопроса: Are there more big green things than large purple shiny cubes?\n",
      "Пример ответа: yes\n"
     ]
    }
   ],
   "source": [
    "def load_clevr_questions(data_dir):\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    # Проходим по каждому разделу: train и val\n",
    "    for split in ['CLEVR_train', 'CLEVR_val']:\n",
    "        # Формируем путь к файлу вопросов\n",
    "        questions_file = os.path.join(data_dir, f'{split}_questions.json')\n",
    "        print(questions_file)  # Для проверки, выводим путь к файлу\n",
    "\n",
    "        # Проверяем, существует ли файл перед его открытием\n",
    "        if not os.path.exists(questions_file):\n",
    "            raise FileNotFoundError(f'Файл не найден: {questions_file}')\n",
    "\n",
    "        # Загружаем данные из файла вопросов\n",
    "        with open(questions_file, 'r') as f:\n",
    "            question_data = json.load(f)\n",
    "\n",
    "        # Извлекаем вопросы и ответы\n",
    "        for item in question_data['questions']:\n",
    "            questions.append(item['question'])\n",
    "            answers.append(item['answer'])\n",
    "\n",
    "    return questions, answers\n",
    "\n",
    "# Пример использования\n",
    "CLEVR_DATA_DIR = 'C:/Users/Dasha/Desktop/CLEVR_v1.0'\n",
    "\n",
    "# Загрузка данных\n",
    "try:\n",
    "    questions, answers = load_clevr_questions(CLEVR_DATA_DIR)\n",
    "    print(f\"Количество вопросов: {len(questions)}\")\n",
    "    print(f\"Пример вопроса: {questions[0]}\")\n",
    "    print(f\"Пример ответа: {answers[0]}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Ошибка при загрузке данных: файл не является корректным JSON.\") \n",
    "except Exception as e:\n",
    "    print(f\"Произошла ошибка: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317deaf9-2f80-406a-8806-302421d98c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример простой токенизации (вам может понадобиться более сложный подход)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_answers = label_encoder.fit_transform(answers)\n",
    "\n",
    "# Преобразование вопросов в векторы (необходима реализация)\n",
    "# Здесь вам нужно будет создать векторы для вопросов, возможно, используя Embedding слой.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51224d38-26d8-4735-947b-9e23d02de2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dasha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5386 - loss: 0.7015\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5215 - loss: 0.6968\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5085 - loss: 0.6916\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5171 - loss: 0.6929\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5585 - loss: 0.6875\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5883 - loss: 0.6828\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5837 - loss: 0.6779\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5232 - loss: 0.6897\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6083 - loss: 0.6660\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6028 - loss: 0.6597\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">296,837</span> (1.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m296,837\u001b[0m (1.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,945</span> (386.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,945\u001b[0m (386.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,892</span> (773.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m197,892\u001b[0m (773.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "# Параметры\n",
    "num_objects = 10  # Количество объектов (например, временные шаги)\n",
    "embedding_dim = 64  # Размерность встраивания (например, размер вектора признаков)\n",
    "\n",
    "# Пример случайных данных для обучения (замените на ваши данные)\n",
    "x_train = np.random.rand(1000, num_objects, embedding_dim)  # Случайные данные\n",
    "y_train = np.random.randint(0, 2, size=(1000,))  # Случайные метки для бинарной классификации (0 или 1)\n",
    "\n",
    "# Создание модели\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(num_objects, embedding_dim), return_sequences=False))  # return_sequences=False для одного выхода\n",
    "model.add(Dense(1, activation='sigmoid'))  # Выходной слой для бинарной классификации\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Вывод структуры модели\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "my_python_2_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
