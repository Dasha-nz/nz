{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "06b1a720-5e13-46f1-b8ec-44f1e033a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество вопросов: 849980\n",
      "Пример вопроса: Are there more big green things than large purple shiny cubes?\n",
      "Пример ответа: yes\n",
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.4663 - loss: 0.8079\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5343 - loss: 0.6867\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7528 - loss: 0.5664\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8796 - loss: 0.2771\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9697 - loss: 0.1222\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9857 - loss: 0.0370\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 5.7490e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 2.9540e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_14… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_15… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">64,000</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m,    │        \u001b[38;5;34m896\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_14… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_15… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m64,000\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m1,605,760\u001b[0m │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m98,816\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,413,445</span> (20.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,413,445\u001b[0m (20.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,804,481</span> (6.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,804,481\u001b[0m (6.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,608,964</span> (13.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,608,964\u001b[0m (13.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf #библиотека с открытым исходным кодом для машинного обучения, предоставляет собой инструменты \n",
    "#для создания и тренировки нейронных сетей и других алгоритмов машинного обучения\n",
    "from tensorflow import keras #высокоуровневая API для создания и обучения нейронных сетей, интегрированая в TensorFlow\n",
    "#Используется для построения и тренировки моделей.\n",
    "from tensorflow.keras import layers #позволяет использовать различные слои, доступные в Keras\n",
    "import numpy as np #библиотека для работы с многомерными массивами и матрицами, а также для выполнения математических\n",
    "#операций над ними,помогает обрабатывать и манипулировать данными\n",
    "import json # для загрузки вопросов из датасета\n",
    "import os #библиотека для взаимодействия с операционной системой\n",
    "\n",
    "\n",
    "def create_image_model(input_shape): # создание функции create_image_model, которая принимает один параметр — input_shape\n",
    "    #он указывает, какого размера будут входные данные\n",
    "    inputs = layers.Input(shape=input_shape)# создание входного слоя, который будет принимать изображения в указанном формате\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs) # обавление свёрточного слоя, который использует 32 фильтра \n",
    "    #размером 3x3,он помогает модели находить важные детали в изображениях\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x) # добавление слоя подвыборки, он уменьшает размер изображения в два раза,\n",
    "    #сохраняя только самое важное\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x) # свёрточный слой, с 64 фильтрами, этот слой ищет детали в изображении\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x) # слой подвыборки для дальнейшего уменьшения размера данных\n",
    "    x = layers.Flatten()(x) # преобразование многомерных данных (которые получились после всех свёрток и подвыборок) в \n",
    "    #одномерный вектор, для того чтобы передать данные в следующий слой\n",
    "    x = layers.Dense(128, activation='relu')(x) # добавление полносвязного слоя с 128 нейронами для того, чтобы модели \n",
    "    #могли делать более сложные выводы на основе извлеченных признаков\n",
    "    model = keras.Model(inputs, x) # создание модели, которая связывает входные данные с выходом для понимания, как \n",
    "    #будет выглядеть модель\n",
    "    return model # возвращение созданной модели, чтобы ее можно было использовать для обучения и предсказаний\n",
    "\n",
    "def create_text_model(vocab_size, embedding_dim, input_length): # функция create_text_model принимает три параметра:\n",
    "#vocab_size — количество уникальных слов в словаре\n",
    "#embedding_dim — размерность векторного представления каждого слова\n",
    "#input_length — длина входных текстов (количество слов в одном тексте)\n",
    "    \n",
    "    inputs = layers.Input(shape=(input_length,)) # создание входного слоя, который будет принимать последовательности \n",
    "    #слов фиксированной длины input_length\n",
    "    x = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs) # слой встраивания (Embedding), он \n",
    "    #преобразует каждое слово в вектор фиксированной длины (embedding_dim)\n",
    "    # использует словарь размером vocab_size, чтобы сопоставить каждое слово с его векторным представлением\n",
    "    x = layers.LSTM(128)(x) # добавление слоя LSTM (долгая краткосрочная память) с 128 нейронами, он помогает модели \n",
    "    #обрабатывать последовательные данные, такие как текст, и запоминать контекст\n",
    "    model = keras.Model(inputs, x) # создание модели, которая связывает входные данные с выходом (вектором, полученным из LSTM)\n",
    "    return model # возвращение созданной модели, чтобы ее можно было использовать для обучения и предсказаний\n",
    "\n",
    "def create_combined_model(image_model, text_model):  # функция create_combined_model принимает два параметра:\n",
    "# image_model — модель для обработки изображений,\n",
    "# text_model — модель для обработки текстов\n",
    "    \n",
    "    combined_input = layers.concatenate([image_model.output, text_model.output]) # объединение выхода обеих моделей \n",
    "    #(изображений и текста) в один общий вектор, что позволяет модели использовать информацию из обеих источников одновременно\n",
    "    x = layers.Dense(64, activation='relu')(combined_input) # добавление полносвязного слоя с 64 нейронами и функцией \n",
    "    #активации ReLU, он помогает модели извлекать более сложные паттерны из объединенных данных\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)  # \n",
    "    model = keras.Model(inputs=[image_model.input, text_model.input], outputs=outputs) # Ссздание выходноого слоя с \n",
    "    #одним нейроном и функцией \n",
    "    # активации сигмоиды(математическая функция, которая используется в нейронных сетях для преобразования выходных \n",
    "    #значений нейронов в диапазон от 0 до 1), \n",
    "    # он будет использоваться для бинарной классификации, то есть для предсказания двух классов\n",
    "    return model# возвращение созданной модели, чтобы ее можно было использовать для обучения и предсказаний\n",
    "\n",
    "image_input_shape = (64, 64, 3)  # входных изображений, которые будут подаваться в модель, каждое изображение будет \n",
    "#иметь размер 64 на 64 пикселя, и будет в цвете (RGB), что обозначается третьим значением 3\n",
    "vocab_size = 1000  # размер словаря, модель будет учитывать только 1000 уникальных слов\n",
    "embedding_dim = 64  # размерность векторного представления (эмбеддинга) для слов в тексте, каждое слово будет \n",
    "#представлено в виде вектора размером 64\n",
    "max_question_length = 20  # максимальная длина вопросов, которые будут обрабатываться моделью, модель будет \n",
    "#принимать только вопросы длиной до 20 слов\n",
    "\n",
    "\n",
    "image_model = create_image_model(image_input_shape) # создание модели для обработки изображений, используя \n",
    "#заданную форму входных изображений image_input_shape, которая равна (64, 64, 3)\n",
    "# image_model будет представлять собой нейронную сеть, способную обрабатывать и анализировать изображения\n",
    "text_model = create_text_model(vocab_size, embedding_dim, max_question_length) # создание модели для обработки \n",
    "#текста, используя параметры словаря, размерности эмбеддинга и максимальной длины вопросов\n",
    "# text_model будет представлять собой нейронную сеть, способную обрабатывать текстовые данные и извлекать из них смысл\n",
    "combined_model = create_combined_model(image_model, text_model) # создает комбинированную модель, которая объединяет \n",
    "#как модель для обработки изображений, так и модель для обработки текста\n",
    "# combined_model будет представлять собой полную модель, способную одновременно обрабатывать как визуальные, так и \n",
    "#текстовые данные\n",
    "\n",
    "\n",
    "combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # compile подготавливает \n",
    "#модель к обучению\n",
    "# определяет, как модель будет обновлять свои веса во время обучения и какие метрики будут использоваться для оценки \n",
    "#её производительности\n",
    "# optimizer='adam' оптимизатор Adam адаптивно изменяет скорость обучения для каждого параметра\n",
    "# loss='binary_crossentropy' функция потерь, которая будет использоваться для оценки качества предсказаний модели\n",
    "# metrics=['accuracy'] метрики, которые будут отслеживаться во время обучения и оценки модели, accuracy измеряет долю\n",
    "#правильных предсказаний модели по сравнению с общим числом предсказаний\n",
    "\n",
    "\n",
    "def load_clevr_questions(data_dir): # функция load_clevr_questions принимает аргумент data_dir, этот аргумент \n",
    "    #представляет собой путь к директории\n",
    "    questions = [] # пустой список questions, который будет использоваться для хранения загруженных вопросов из набора данных\n",
    "    answers = [] # пустой список answers, который будет использоваться для хранения ответов на вопросы\n",
    "\n",
    "    for split in ['CLEVR_train', 'CLEVR_val']: # цикл for, чтобы пройти по двум значениям: 'CLEVR_train' и 'CLEVR_val'\n",
    "        questions_file = os.path.join(data_dir, f'{split}_questions.json') # создается полное имя файла с вопросами, \n",
    "        #используя os.path.join, чтобы правильно объединить путь к директории data_dir\n",
    "        if not os.path.exists(questions_file): # проверяется существование файла с вопросами по указанному пути, если \n",
    "            #файл не найден, то условие not os.path.exists(questions_file) будет истинным\n",
    "            raise FileNotFoundError(f'Файл не найден: {questions_file}') # если файл не найден, будет вызвано исключение \n",
    "            #FileNotFoundError, и будет выведено сообщение о том, какой именно файл не найден\n",
    "\n",
    "        with open(questions_file, 'r') as f: #  with автоматически закроет файл после завершения блока кода, даже если \n",
    "            #возникнет ошибка\n",
    "            # open(questions_file, 'r') открывает файл, путь к которому хранится в переменной questions_file,\n",
    "            #в режиме чтения ('r')\n",
    "            # as f присваивает открытый файл переменной f, чтобы можно было ссылаться на него внутри блока with\n",
    "            question_data = json.load(f) # функция json.load() загружает содержимое файла f в формате JSON и \n",
    "            #преобразовать его в соответствующий объект Python\n",
    "             #question_data теперь будет содержать данные, которые были в файле questions_file\n",
    "\n",
    "        for item in question_data['questions']: # for проходится по каждому элементу в списке questions, который \n",
    "            #находится в загруженных данных question_data\n",
    "            # question_data —словарь, содержащий ключ 'questions', значение которого является списком, содержащим \n",
    "            #словари с вопросами и ответами\n",
    "            questions.append(item['question']) # внутри цикла идет обращение к текущему элементу item, который \n",
    "            #представляет собой словарь, содержащий информацию о вопросе и ответе\n",
    "            # item['question'] извлекает текст вопроса из текущего элемента, и добавляет его в список questions с \n",
    "            #помощью метода append(), это собирает все вопросы в одном списке\n",
    "            answers.append(item['answer']) # идет извлечение ответа из текущего элемента с помощью item['answer'] и \n",
    "            #добавление его в список answers\n",
    "            # после выполнения этого цикла будет два списка: один с вопросами и другой с соответствующими ответами\n",
    "\n",
    "    return questions, answers # возвращение двух списков: один с вопросами и другой с ответами для того, чтобы \n",
    "    #использовать эти списки в других частях программы\n",
    "\n",
    "\n",
    "CLEVR_DATA_DIR = 'C:/Users/Dasha/Desktop/CLEVR_v1.0' # путь к папке с данными\n",
    "\n",
    "try: # в блоке try программа выполняет функцию load_clevr_questions, которая загружает вопросы\n",
    "    #и ответы из указанной папки\n",
    "    questions, answers = load_clevr_questions(CLEVR_DATA_DIR) # в переменные questions и answers \n",
    "    #записываются загруженные данные\n",
    "    \n",
    "    print(f\"Количество вопросов: {len(questions)}\")\n",
    "    print(f\"Пример вопроса: {questions[0]}\")\n",
    "    print(f\"Пример ответа: {answers[0]}\")\n",
    "    \n",
    "except FileNotFoundError as e: # \n",
    "    print(e) # \n",
    "except json.JSONDecodeError: # \n",
    "    print(\"Ошибка при загрузке данных: файл не является корректным JSON.\") # \n",
    "except Exception as e: # \n",
    "    print(f\"Произошла ошибка: {e}\") # \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder # импортируется LabelEncoder из библиотеки sklearn, которая \n",
    "#используется для обработки данных\n",
    "\n",
    "label_encoder = LabelEncoder() # создание объекта label_encoder, который будет\n",
    "#использоваться для преобразования\n",
    "#текстовых ответов в числовые значения\n",
    "encoded_answers = label_encoder.fit_transform(answers) # метод fit_transform для преобразования\n",
    "#списка answers в числовой формат\n",
    "\n",
    "num_samples = 1000 # количество примеров, которые генерируются для тренировки модели\n",
    "x_image_train = np.random.rand(num_samples, *image_input_shape)  # генерируются случайные числа для\n",
    "#изображений, которые будут использоваться для тренировки модели\n",
    "# используется функция np.random.rand из библиотеки NumPy, которая генерирует случайные числа\n",
    "#в диапазоне от 0 до 1\n",
    "# num_samples - количество примеров, которое генерируется\n",
    "# *image_input_shape - это форма входного изображения\n",
    "x_text_train = np.random.randint(0, vocab_size, size=(num_samples, max_question_length))\n",
    "# генерируются случайные целые числа для текстовых данных, которые будут использоваться для тренировки модели\n",
    "# используется функция np.random.randint из библиотеки NumPy, которая генерирует случайные целые числа\n",
    "#в диапазоне от 0 до vocab_size\n",
    "# num_samples - количество примеров, которое генерируется\n",
    "# max_question_length - максимальная длина текстового вопроса\n",
    "# vocab_size - количество уникальных слов в словаре (vocabularly)\n",
    "y_train = np.random.randint(0, 2, size=(num_samples,))  # генерируются случайные метки (labels)\n",
    "#для тренировки модели\n",
    "# используется функция np.random.randint из библиотеки NumPy, которая генерирует случайные целые\n",
    "#числа в диапазоне от 0 до 1\n",
    "\n",
    "\n",
    "combined_model.fit([x_image_train, x_text_train], y_train, epochs=10, batch_size=32) \n",
    "# x_image_train и x_text_train - это входные данные для модели, они представляют\n",
    "#собой изображения и текстовые данные\n",
    "# y_train - это метки (labels) для данных, которые были сгенерированы, они представляют\n",
    "#собой классификацию данных (0 или 1)\n",
    "# epochs=10 - это количество эпох для обучения модели, одна эпоха - это один проход по всем данным\n",
    "# batch_size=32 - это количество примеров, которые обрабатываются за один шаг\n",
    "\n",
    "\n",
    "combined_model.summary() # информация о структуре модели combined_model для понимания,\n",
    "как работает модель и какие слои она содержит\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "my_python_2_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
