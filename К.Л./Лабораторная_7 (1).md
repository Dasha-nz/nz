!python -m nltk.downloader all


```python
# Импорт необходимых библиотек
import pandas as pd  # Импорт библиотеки pandas для работы с данными в формате таблиц (DataFrame)
import numpy as np  # Импорт библиотеки numpy для работы с массивами и числовыми операциями
from sklearn.model_selection import train_test_split  # Импорт функции для разделения данных на обучающую и тестовую выборки
from sklearn.metrics import classification_report  # Импорт функции для оценки качества классификации
from sklearn.feature_extraction.text import CountVectorizer  # Импорт векторизатора для преобразования текста в числовые векторы
from sklearn.naive_bayes import MultinomialNB  # Импорт модели наивного байесовского классификатора
import nltk  # Импорт библиотеки Natural Language Toolkit для обработки естественного языка
from nltk.stem import WordNetLemmatizer  # Импорт класса для лемматизации слов
from nltk.tokenize import word_tokenize  # Импорт функции для токенизации текста

# Установка необходимых ресурсов NLTK
nltk.download('punkt')  # Загрузка ресурса для токенизации
nltk.download('wordnet')  # Загрузка лексикона WordNet для лемматизации

# Создание искусственного набора данных
data = pd.DataFrame({  # Создание DataFrame с текстом и соответствующими метками
    'text': [
        'Я люблю этот продукт',  # положительный
        'Это худший опыт в моей жизни',  # отрицательный
        'Просто нормально',  # нейтральный
        'Отличная работа!',  # положительный
        'Мне не понравилось',  # отрицательный
        'Это было неплохо',  # нейтральный
        'Я в восторге от сервиса',  # положительный
        'Ужасный фильм',  # отрицательный
    ],
    'label': [
        'positive',  # Метка для положительного отзыва
        'negative',  # Метка для отрицательного отзыва
        'neutral',  # Метка для нейтрального отзыва
        'positive',  # Метка для положительного отзыва
        'negative',  # Метка для отрицательного отзыва
        'neutral',  # Метка для нейтрального отзыва
        'positive',  # Метка для положительного отзыва
        'negative',  # Метка для отрицательного отзыва
    ]
})

print(data)  # Вывод созданного DataFrame для проверки данных

# Простой словарь тональностей
sentiment_dict = {  # Словарь для оценки тональности слов
    'люблю': 1,  # Положительное слово
    'худший': -1,  # Отрицательное слово
    'нормально': 0,  # Нейтральное слово
    'отличная': 1,  # Положительное слово
    'не понравилось': -1,  # Отрицательное слово
    'неплохо': 0,  # Нейтральное слово
    'в восторге': 1,  # Положительное слово
    'ужасный': -1,  # Отрицательное слово
}

def get_sentiment_score(text):  # Функция для вычисления тональности текста
    score = 0  # Инициализация переменной для хранения суммы тональности
    for word in text.split():  # Проход по каждому слову в тексте
        score += sentiment_dict.get(word.lower(), 0)  # Добавление тональности слова к общей сумме (по умолчанию 0)
    return score  # Возврат итогового балла тональности

data['sentiment_score'] = data['text'].apply(get_sentiment_score)  # Применение функции для расчета тональности к каждому тексту
print(data[['text', 'sentiment_score']])  # Вывод текста и его тональности

# Лемматизация текста
lemmatizer = WordNetLemmatizer()  # Создание объекта для лемматизации

def lemmatize_text(text):  # Функция для лемматизации текста
    tokens = word_tokenize(text)  # Токенизация текста на слова
    return ' '.join([lemmatizer.lemmatize(token) for token in tokens])  # Лемматизация каждого токена и объединение обратно в строку

data['lemmatized_text'] = data['text'].apply(lemmatize_text)  # Применение лемматизации к каждому тексту
X = data['lemmatized_text']  # Определение переменной X с лемматизированным текстом
y = data['label']  # Определение переменной y с метками

# Разделение данных на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Разделение данных на 80% для обучения и 20% для тестирования

# Векторизация текста
vectorizer = CountVectorizer()  # Создание объекта для векторизации текста
X_train_vectorized = vectorizer.fit_transform(X_train)  # Векторизация обучающей выборки
X_test_vectorized = vectorizer.transform(X_test)  # Векторизация тестовой выборки

# Обучение модели Naive Bayes
model = MultinomialNB()  # Создание экземпляра модели наивного байесовского классификатора
model.fit(X_train_vectorized, y_train)  # Обучение модели на векторизованных данных

# Предсказание на тестовой выборке
y_pred = model.predict(X_test_vectorized)  # Предсказание меток для тестовой выборки

# Отчет о качестве классификации
print(classification_report(y_test, y_pred, zero_division=0))  # Вывод отчета о качестве классификации, включая метрики точности, полноты и F1

```

    [nltk_data] Downloading package punkt to /root/nltk_data...
    [nltk_data]   Package punkt is already up-to-date!
    [nltk_data] Downloading package wordnet to /root/nltk_data...
    [nltk_data]   Package wordnet is already up-to-date!
    

                               text     label
    0          Я люблю этот продукт  positive
    1  Это худший опыт в моей жизни  negative
    2              Просто нормально   neutral
    3              Отличная работа!  positive
    4            Мне не понравилось  negative
    5              Это было неплохо   neutral
    6       Я в восторге от сервиса  positive
    7                 Ужасный фильм  negative
                               text  sentiment_score
    0          Я люблю этот продукт                1
    1  Это худший опыт в моей жизни               -1
    2              Просто нормально                0
    3              Отличная работа!                1
    4            Мне не понравилось                0
    5              Это было неплохо                0
    6       Я в восторге от сервиса                0
    7                 Ужасный фильм               -1
                  precision    recall  f1-score   support
    
        negative       0.00      0.00      0.00       1.0
         neutral       0.00      0.00      0.00       1.0
        positive       0.00      0.00      0.00       0.0
    
        accuracy                           0.00       2.0
       macro avg       0.00      0.00      0.00       2.0
    weighted avg       0.00      0.00      0.00       2.0
    
    
